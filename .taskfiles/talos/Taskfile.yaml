---
version: "3"

vars:
  N: '{{ .N | default "0" }}'
  NODE_LIST:
    sh: yq '.nodes | keys | join(",")' < {{.TALOS_DIR}}/talconfig.yaml
  # renovate: datasource=docker depName=ghcr.io/siderolabs/installer
  TALOS_VERSION: "v1.9.5"
  # renovate: datasource=docker depName=ghcr.io/siderolabs/kubelet
  KUBERNETES_VERSION: "v1.32.4"
  # renovate: datasource=github-releases depName=budimanjojo/talhelper
  TALHELPER: "v3.0.23"
  TALOS_CONTROLLER:
    sh: talosctl config info --output json | jq --raw-output '.endpoints[]' | shuf -n 1

tasks:
  init:
    desc: Init talosctl and grab kubeconfig (task talos:init)
    cmds:
      - task: install
      - task: generate
      - task: generate-kubeconfig

  install:
    desc: Install talos and talhelper (task talos:install)
    cmds:
      - task: install:talos
      - task: install:talhelper

  install:talos:
    internal: true
    desc: Install talos and talhelper (task talos:install)
    cmds:
      - sudo rm -f /usr/local/bin/talosctl
      - curl -sL https://talos.dev/install | sed "s+siderolabs/talos/releases/latest/download+siderolabs/talos/releases/download/{{ .TALOS_VERSION }}+g" | bash
    generates:
      - /usr/local/bin/talosctl
    status:
      - talosctl version --client --short | grep -q 'Client {{ .TALOS_VERSION }}'

  install:talhelper:
    internal: true
    desc: Install talos and talhelper (task talos:install)
    cmds:
      - curl https://i.jpillora.com/budimanjojo/talhelper@{{ .TALHELPER }}\! | sudo bash
    generates:
      - /usr/local/bin/talhelper
    status:
      - talhelper --version | grep -q 'talhelper version {{ trimPrefix "v" .TALHELPER }}'

  dashboard:
    desc: Show talos dashboard fot N node (task talos:dashboard)
    vars:
      NODE:
        sh: yq ".nodes[{{ .N }}].ipAddress" < {{.TALOS_DIR}}/talconfig.yaml
      NODE_NAME:
        sh: yq ".nodes[{{ .N }}].hostname" < {{.TALOS_DIR}}/talconfig.yaml
    cmds:
      - task: generate
      - talosctl --talosconfig={{.TALOS_DIR}}/clusterconfig/talosconfig --nodes {{ .NODE }} dashboard

  shutdown:
    desc: Shutdown talos N node (task talos:shutdown N=X)
    vars:
      NODE:
        sh: yq ".nodes[{{ .N }}].ipAddress" < {{.TALOS_DIR}}/talconfig.yaml
      NODE_NAME:
        sh: yq ".nodes[{{ .N }}].hostname" < {{.TALOS_DIR}}/talconfig.yaml
    cmds:
      - task: generate
      - task: wait_for_health
        vars: {TIMEOUT: 10m}
      - talosctl --talosconfig={{.TALOS_DIR}}/clusterconfig/talosconfig --nodes {{ .NODE }} shutdown --wait

  upgrade:k8s:
    dir: provision/talos
    desc: Upgrade Kubernetes to {{ .KUBERNETES_VERSION }} (task talos:upgrade:k8s)
    vars:
      NODE:
        sh: yq ".nodes[{{ .N }}].ipAddress" < {{.TALOS_DIR}}/talconfig.yaml
      NODE_NAME:
        sh: yq ".nodes[{{ .N }}].hostname" < {{.TALOS_DIR}}/talconfig.yaml
    cmds:
      - task: init
      - talosctl --nodes {{ .NODE }} upgrade-k8s --to {{ .KUBERNETES_VERSION }}

  upgrade:all:
    desc: Upgrade all nodes to Talos version {{ .TALOS_VERSION }} (task talos:upgrade:all)
    dir: provision/talos
    cmds:
      - task: init
      # nodes
      - for:
          var: NODE_LIST
          split: ','
        task: upgrade
        vars:
          N: '{{.ITEM}}'
      - task: wait_for_health
        vars: {TIMEOUT: 10m}

  apply:restart:
    desc: Apply Talos config to a specific node with reboot (task talos:apply:restart N=X)
    dir: provision/talos
    vars:
      NODE:
        sh: yq ".nodes[{{ .N }}].ipAddress" < {{.TALOS_DIR}}/talconfig.yaml
      NODE_NAME:
        sh: yq ".nodes[{{ .N }}].hostname" < {{.TALOS_DIR}}/talconfig.yaml
    cmds:
      - task: generate
      - task: wait_for_health
        vars: {TIMEOUT: 10m}
      - task: apply-config
        vars: {CLI_ARGS: "-m staged"}
      - talosctl reboot --nodes {{ .NODE }} --wait
      - talosctl --nodes {{.NODE}} health --wait-timeout=10m --server=false

  apply:
    desc: Apply Talos config to a specific node without reboot (task talos:apply N=X)
    dir: provision/talos
    vars:
      NODE:
        sh: yq ".nodes[{{ .N }}].ipAddress" < {{.TALOS_DIR}}/talconfig.yaml
      NODE_NAME:
        sh: yq ".nodes[{{ .N }}].hostname" < {{.TALOS_DIR}}/talconfig.yaml
    cmds:
      - task: generate
      - task: wait_for_health
        vars: {TIMEOUT: 10m}
      - task: apply-config
        vars: {CLI_ARGS: "-m auto"}
      - talosctl --nodes {{.NODE}} health --wait-timeout=10m --server=false

  apply:reinstall:
    desc: Apply Talos config to a specific node without reboot (task talos:apply:reinstall N=X FORCE=false)
    dir: provision/talos
    cmds:
      - task: generate
      - task: upgrade

  generate-kubeconfig:
    internal: true
    desc: Generate Talos kubeconfig (task talos:generate-kubeconfig)
    dir: provision/talos
    vars:
      NODE:
        sh: yq ".nodes[{{ .N }}].ipAddress" < {{.TALOS_DIR}}/talconfig.yaml
      NODE_NAME:
        sh: yq ".nodes[{{ .N }}].hostname" < {{.TALOS_DIR}}/talconfig.yaml
    cmds:
      - cmd: talosctl --talosconfig={{.TALOS_DIR}}/clusterconfig/talosconfig kubeconfig -f --nodes {{ .NODE }} $KUBECONFIG
    status:
      - test -f $KUBECONFIG

  generate:
    internal: true
    desc: Generate Talos machine configurations (task talos:generate)
    dir: provision/talos
    cmds:
      - talhelper genconfig
    sources:
      - talconfig.yaml
      - talenv.sops.yaml
      - talenv.yaml
      - talsecret.sops.yaml
    generates:
      - clusterconfig/*.yaml
      - clusterconfig/talosconfig
    preconditions:
      - test -f {{.TALOS_DIR}}/talconfig.yaml

  apply-config:
    internal: true
    desc: Apply Talos config to a specific node (task talos:apply N=X)
    dir: provision/talos
    vars:
      NODE:
        sh: yq ".nodes[{{ .N }}].ipAddress" < {{.TALOS_DIR}}/talconfig.yaml
      NODE_NAME:
        sh: yq ".nodes[{{ .N }}].hostname" < {{.TALOS_DIR}}/talconfig.yaml
      FILE:
        sh: ls {{.TALOS_DIR}}/clusterconfig/home-{{ .NODE_NAME }}.yaml
    cmds:
      - talosctl apply-config --nodes {{ .NODE }} --file {{.FILE}} {{ .CLI_ARGS }}
    preconditions:
      - test -f {{.TALOS_DIR}}/talconfig.yaml

  upgrade:
    internal: true
    desc: Upgrade a single node to Talos version {{ .TALOS_VERSION }} (task talos:upgrade N=X)
    dir: provision/talos
    vars:
      NODE:
        sh: yq ".nodes[{{ .N }}].ipAddress" < {{.TALOS_DIR}}/talconfig.yaml
      NODE_NAME:
        sh: yq ".nodes[{{ .N }}].hostname" < {{.TALOS_DIR}}/talconfig.yaml
      FILE:
        sh: ls {{.TALOS_DIR}}/clusterconfig/home-{{ .NODE_NAME }}.yaml
      TALOS_IMAGE:
        sh: yq ea '[.machine.install.image].[0]' < "{{.FILE}}"
      FORCE: "{{ .FORCE | default false }}"
    status:
      - $([ "{{ .FORCE }}" = "false" ] && talosctl version --nodes {{ .NODE }} --short | grep -q 'Tag.*v1.9.5' || return 1)
    cmds:
      - task: wait_for_health
        vars: {TIMEOUT: 10m}
      - task: apply-config
        vars: {N: "{{ .N }}", CLI_ARGS: "-m staged"}
      - talosctl upgrade --nodes {{ .NODE }} --image {{ .TALOS_IMAGE }}
      - talosctl --nodes {{.NODE}} health --wait-timeout=10m --server=false


  wait_for_health:
    internal: true
    desc: Wait for services in cluster to be healthy
    cmds:
      - kubectl wait --timeout=5m --for=condition=Complete jobs --all --all-namespaces
      # Ensure CephCluster is healthy
      - kubectl -n rook-ceph wait --for jsonpath='{.status.ceph.health}'='HEALTH_OK' --timeout {{ .TIMEOUT | default "30s" }} cephcluster rook-ceph
      # Ensure CloudNative-PG cluster has 2 ready instances
      # - kubectl -n gitea wait --for jsonpath='{.status.readyInstances}'='2' --timeout {{ .TIMEOUT | default "30s" }} cluster giteadb-cnpg
      - kubectl -n identity wait --for jsonpath='{.status.readyInstances}'='2' --timeout {{ .TIMEOUT | default "30s" }} cluster keycloakdb-cnpg

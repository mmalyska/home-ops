---
# yaml-language-server: $schema=https://raw.githubusercontent.com/budimanjojo/talhelper/master/pkg/config/schemas/talconfig.json

clusterName: &clusterName home

# renovate: datasource=docker depName=ghcr.io/siderolabs/installer
talosVersion: v1.10.6
# renovate: datasource=docker depName=ghcr.io/siderolabs/kubelet
kubernetesVersion: v1.32.9

endpoint: https://${clusterDomain}:6443
cniConfig:
  name: none

additionalMachineCertSans: &sans
  - &talosControlplaneVip ${clusterEndpointIP}
  - ${clusterDomain}
  - 127.0.0.1 # KubePrism
additionalApiServerCertSans: *sans

clusterPodNets: ["10.244.0.0/16"]
clusterSvcNets: ["10.96.0.0/12"]

nodes:
  - hostname: mc1
    ipAddress: 192.168.48.2
    installDisk: /dev/nvme0n1
    controlPlane: true
    networkInterfaces:
      - interface: eth0
        addresses:
          - 192.168.48.2/22
        mtu: 1500
        routes:
          - network: 0.0.0.0/0
            gateway: 192.168.50.1
        vip:
          ip: *talosControlplaneVip
  - hostname: mc2
    ipAddress: 192.168.48.3
    installDisk: /dev/nvme0n1
    controlPlane: true
    networkInterfaces:
      - interface: eth0
        addresses:
          - 192.168.48.3/22
        mtu: 1500
        routes:
          - network: 0.0.0.0/0
            gateway: 192.168.50.1
        vip:
          ip: *talosControlplaneVip
  - hostname: mc3
    ipAddress: 192.168.48.4
    installDisk: /dev/nvme0n1
    controlPlane: true
    networkInterfaces:
      - interface: eth0
        addresses:
          - 192.168.48.4/22
        mtu: 1500
        routes:
          - network: 0.0.0.0/0
            gateway: 192.168.50.1
        vip:
          ip: *talosControlplaneVip
  - hostname: nv1
    ipAddress: 192.168.48.5
    installDisk: /dev/nvme0n1
    controlPlane: false
    schematic:
      customization:
        extraKernelArgs:
          - -selinux
          - console=tty0
          - console=ttyS0,115200
          - sysctl.kernel.kexec_load_disabled=1
          - talos.dashboard.disabled=1
          - talos.auditd.disabled=1
        # systemExtensions:
        #   officialExtensions:
        #     - siderolabs/nvidia-container-toolkit-production
    networkInterfaces:
      - interface: enP8p1s0
        addresses:
          - 192.168.48.5/22
        mtu: 1500
        routes:
          - network: 0.0.0.0/0
            gateway: 192.168.50.1
    nodeTaints:
      nv: :NoSchedule
    patches:
      - |-
        machine:
          sysctls:
            net.core.bpf_jit_harden: 1    # Nvidia CLI


controlPlane:
  nodeLabels: &nodeLabels
    topology.kubernetes.io/region: *clusterName
    topology.kubernetes.io/zone: m

  extensionServices: &extensionServices
    - name: nut-client
      configFiles:
        - mountPath: /usr/local/etc/nut/upsmon.conf
          content: |
            MONITOR ${upsmonHost} 1 ${upsmonUser} ${upsmonPasswd} secondary
            SHUTDOWNCMD "/sbin/poweroff"

  schematic:
    customization:
      extraKernelArgs:
        - -selinux                            # Less security, more speed
        - apparmor=0                          # Less security, more speed
        - init_on_alloc=0                     # Less security, more speed
        - init_on_free=0                      # Less security, more speed
        - intel_iommu=on                      # PCI Passthrough
        - iommu=pt                            # PCI Passthrough
        - mitigations=off                     # Less security, more speed
        - security=none                       # Less security, more speed
        - net.ifnames=0                       # Disable predictable NIC naming
        - talos.auditd.disabled=1             # Less security, faster puter

      systemExtensions:
        officialExtensions:
          - siderolabs/i915
          - siderolabs/intel-ucode
          - siderolabs/nut-client

  patches:
    # Configure containerd
    - &patchContainerd |-
      machine:
        files:
          - op: create
            path: /etc/cri/conf.d/20-customization.part
            content: |
              [plugins]
                [plugins."io.containerd.grpc.v1.cri"]
                  enable_unprivileged_ports = true
                  enable_unprivileged_icmp = true
              [plugins."io.containerd.grpc.v1.cri".containerd]
                discard_unpacked_layers = false
              [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
                discard_unpacked_layers = false

    # Disable Host DNS
    - &patchHostDNS |-
      machine:
        features:
          hostDNS:
            enabled: true
            resolveMemberNames: true
            forwardKubeDNSToHost: false

    # Configure kubelet
    - &patchKubelet |-
      machine:
        kubelet:
          extraArgs:
            rotate-server-certificates: "true"

    # Enable KubePrism
    - &patchKubePrism |-
      machine:
        features:
          kubePrism:
            enabled: true
            port: 7445

    # Configure custom sysctls
    - |-
      machine:
        sysctls:
          fs.inotify.max_user_instances: 8192    # Watchdog
          fs.inotify.max_user_watches: 1048576   # Watchdog
          net.core.rmem_max: 67108864            # Cloudflared / QUIC
          net.core.wmem_max: 67108864            # Cloudflared / QUIC
          vm.nr_hugepages: 1024                  # Postgres

    # Enable K8s Talos API Access
    - &patchTalosAPIAccess |-
      machine:
        features:
          kubernetesTalosAPIAccess:
            enabled: true
            allowedRoles:
              - os:etcd:backup
            allowedKubernetesNamespaces:
              - talos-backup

    # Configure time server
    - &patchTimeServer |-
      machine:
        time:
          disabled: false
          servers:
            - 192.168.50.1

    # Configure main DNS
    - &patchDNS |-
      machine:
        network:
          nameservers:
            - 192.168.50.9

    # Various udev rules
    - |-
      machine:
        udev:
          rules:
            # Intel GPU
            - SUBSYSTEM=="drm", KERNEL=="renderD*", GROUP="44", MODE="0660"

    # Configure cluster
    - |-
      cluster:
        allowSchedulingOnMasters: true
        coreDNS:
          disabled: true
        proxy:
          disabled: true
        apiServer:
          extraArgs:
            oidc-client-id: ${oidcClientId}
            oidc-groups-claim: groups
            oidc-groups-prefix: 'oidc:'
            oidc-issuer-url: ${oidcIssuerURL}
            oidc-username-claim: email
            oidc-username-prefix: 'oidc:'

    # Configure bind-address
    - &patchBindAddress |-
      - op: add
        path: /cluster/controllerManager/extraArgs
        value:
          bind-address: 0.0.0.0
      - op: add
        path: /cluster/scheduler/extraArgs
        value:
          bind-address: 0.0.0.0
      - op: add
        path: /cluster/proxy/extraArgs
        value:
          bind-address: 0.0.0.0

worker:
  nodeLabels: *nodeLabels
  extensionServices: *extensionServices
  schematic:
    customization:
      systemExtensions:
        officialExtensions:
          - nut-client
  patches:
    - *patchContainerd
    - *patchHostDNS
    - *patchTimeServer
    - *patchDNS
